# -*- coding: utf-8 -*-
"""MLProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ejnTwRsHke9FKWxU_5qihvWd_HvdxBVn

# Wstępna obróbka danych

##wstep do sprawka, stad usunac, dodac do docs,przeczytac i przeanalizowac
**Wprowadzenie do Uczenia Maszynowego w Przewidywaniu Chorób Układu Sercowo-Naczyniowego**

Choroby układu sercowo-naczyniowego (CVD) stanowią istotny problem zdrowotny na skalę globalną, odpowiadając za znaczną część rocznej liczby zgonów na całym świecie. Ze względu na ich powszechność oraz wpływ na umieralność, wczesne wykrywanie i skuteczne zarządzanie CVD stanowią priorytet. Techniki uczenia maszynowego pojawiły się jako potężne narzędzia w opiece zdrowotnej, oferując potencjał analizy złożonych zbiorów danych oraz pomoc w modelowaniu predykcyjnym w diagnostyce chorób i ocenie ryzyka.

Badany zbiór danych zawiera istotne informacje zebrane z różnych źródeł, konsolidując różnorodne atrybuty związane ze zdrowiem układu sercowo-naczyniowego. Obejmuje 11 kluczowych cech, takich jak wiek, płeć, ciśnienie krwi, poziom cholesterolu czy wyniki elektrokardiogramu. Te atrybuty zostały zebrane z pięciu odrębnych zbiorów danych, w tym obserwacje z takich źródeł jak zbiory danych z Cleveland, Węgier, Szwajcarii, Long Beach VA i Stalog. Połączenie tych danych skutkuje kompleksowym zbiorem danych zawierającym 918 obserwacji, co czyni go jednym z najobszerniejszych źródeł dostępnych do badań nad chorobami układu sercowo-naczyniowego.

Celem analizy jest wykorzystanie algorytmów uczenia maszynowego do przewidywania prawdopodobieństwa wystąpienia chorób serca na podstawie tych różnorodnych atrybutów. Cechy zbioru danych oferują bogaty wachlarz informacji, które potencjalnie mogą być wykorzystane do opracowania modeli predykcyjnych. Wykorzystując potencjał uczenia maszynowego, niniejsze badanie ma na celu przyczynienie się do wczesnego wykrywania i skutecznego zarządzania chorobami układu sercowo-naczyniowego.

W niniejszym sprawozdaniu zostaną omówione kroki preprocessingu, analizy cech, rozwój modeli oraz metryki oceny wykorzystane do stworzenia solidnych modeli predykcyjnych. Ostatecznym celem jest stworzenie niezawodnego narzędzia predykcyjnego, które może pomóc profesjonalistom opieki zdrowotnej w identyfikacji osób narażonych na choroby układu sercowo-naczyniowego, umożliwiając tym samym szybkie interwencje i poprawę wyników leczenia pacjentów.
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score, precision_score
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier, export_graphviz
import pydotplus
from IPython.display import Image
import seaborn as sns
from sklearn.ensemble import BaggingClassifier
from sklearn.ensemble import RandomForestClassifier
from scipy.stats import chi2_contingency
from sklearn.model_selection import cross_val_score, KFold
from imblearn.over_sampling import SMOTE
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC

data = pd.read_csv("heart.csv")

for column in data.columns:
    print(f"Analiza kolumny: {column}")
    print("===========================================")

    dtype = data[column].dtype

    missing_values = data[column].isna().sum()
    print(f"Liczba brakujących wartości: {missing_values}")

    if dtype == 'object':
        # Jeśli kolumna jest kategoryczna
        unique_values = data[column].unique()
        print(f"Unikalne wartości: {unique_values}")
    else:
        # Jeśli kolumna jest liczbowa
        mean_value = data[column].mean()
        min_value = data[column].min()
        max_value = data[column].max()
        std_value = data[column].std()

        print(f"Średnia: {mean_value}")
        print(f"Minimum: {min_value}")
        print(f"Maksimum: {max_value}")
        print(f"Odchylenie standardowe: {std_value}")

    print("\n")

"""Widzimy że nasze dane nie posiadają brakujących wartości."""

selected_columns = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']

plt.figure(figsize=(12, 8))
sns.boxplot(data=data[selected_columns], palette='Set2')
plt.title('Wykresy pudełkowe dla wybranych kolumn')
plt.xlabel('Kolumny')
plt.ylabel('Wartości')
plt.show()

data.head()

"""## Analiza korelacji oraz rozkładów zmiennych"""

corr_matrix_data = data[['Age','RestingBP','Cholesterol','FastingBS','MaxHR','Oldpeak']]
correlation_matrix = corr_matrix_data.corr()

plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Macierz korelacji')
plt.show()

"""Jak możemy zauważyć, korelacje między zmiennymi objaśniającymi nie są duże, a więc możemy przyjąć wszystkie te zmienne do modelu. Następnie przechodzimy do analizowania pozostałych kolumn."""

data.describe(include='object')

fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))

for i, column in enumerate(['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']):
    sns.countplot(x=column, hue='HeartDisease', data=data, ax=axes[i // 3, i % 3])
    axes[i // 3, i % 3].set_title(f'{column} distribution by HeartDisease')

fig.delaxes(axes[1, 2])
plt.tight_layout()
plt.show()

"""Na podstawie analizy rozkładów zmiennych kategorycznych widzimy, że rozkłady te różnią się dla osób chorych i zdrowych, a zatem zmienne te mogą potencjalnie mieć istotny wpływ na przewidywania modelu."""

#Tworzenie wykresów rozkładów zmiennych
fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))

data['ST_Slope'].value_counts().plot(kind='bar', ax=axes[0, 0], title='ST_Slope')

data['ExerciseAngina'].value_counts().plot(kind='bar', ax=axes[0, 1], title='ExerciseAngina')

data['RestingECG'].value_counts().plot(kind='bar', ax=axes[0, 2], title='RestingECG')

data['ChestPainType'].value_counts().plot(kind='bar', ax=axes[1, 0], title='ChestPainType')

data['Sex'].value_counts().plot(kind='bar', ax=axes[1, 1], title='Sex')

# Usunięcie nieużywanych subplotów
fig.delaxes(axes[1, 2])

plt.tight_layout()
plt.show()

"""Po zobrazowaniu liczności klas widzimy, że możemy obliczyć współczynnik V-Cramera, ponieważ klasy są wystarczająco liczne"""

def cramers_v(confusion_matrix):
    chi2 = chi2_contingency(confusion_matrix)[0]
    n = confusion_matrix.sum()
    phi2 = chi2 / n
    r, k = confusion_matrix.shape
    phi2corr = max(0, phi2 - ((k - 1) * (r - 1)) / (n - 1))
    rcorr = r - ((r - 1) ** 2) / (n - 1)
    kcorr = k - ((k - 1) ** 2) / (n - 1)
    return np.sqrt(phi2corr / min((kcorr - 1), (rcorr - 1)))

# Lista kolumn do analizy
columns_to_analyze = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']

# Tworzenie macierzy korelacji V Cramera
corr_matrix = np.zeros((len(columns_to_analyze), len(columns_to_analyze)))

for i, col1 in enumerate(columns_to_analyze):
    for j, col2 in enumerate(columns_to_analyze):
        if i != j:
            confusion_matrix = pd.crosstab(data[col1], data[col2]).values
            correlation = cramers_v(confusion_matrix)
            corr_matrix[i, j] = correlation

# Tworzenie mapy cieplnej
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, xticklabels=columns_to_analyze, yticklabels=columns_to_analyze, cmap='coolwarm')
plt.title('Korelacja V-Cramera między zmiennymi kategorycznymi')
plt.show()

"""Po obliczeniu współczynnika V-Cramera widzimy, że zmienne wykazują znikomą lub umiarkowaną korelacje między sobą. Oznacza to, że wszystkie nasze zmienne możemy pozostawić w zbiorze danych, a następnie przejść do one-hot encoding oraz do balansowania zbioru względnem zmiennej objaśnianej.

one-hot encoding
"""

categorical_columns = data.select_dtypes(include=['object']).columns

# One-Hot Encoding
encoded_data = pd.get_dummies(data, columns=categorical_columns)

encoded_data.head()

"""## Analiza zbalansowania zbioru względem zmiennej objaśnianej

"""

print(data['HeartDisease'].value_counts())

"""##Podział na zbiór testowy i uczący  - wybór random seed

"""

def calculate_balance(seed):
    X_train, X_test, y_train, y_test = train_test_split(encoded_data.drop('HeartDisease', axis=1),
                                                        encoded_data['HeartDisease'],
                                                        test_size=0.2,
                                                        random_state=seed)

    # Obliczenie zbalansowania danych w zbiorze uczącym
    balance_train = abs(y_train.value_counts(normalize=True)[0] - y_train.value_counts(normalize=True)[1])

    # Obliczenie zbalansowania danych w zbiorze testowym
    balance_test = abs(y_test.value_counts(normalize=True)[0] - y_test.value_counts(normalize=True)[1])

    # Liczba obserwacji dla klas 0 i 1 w zbiorze uczącym
    class_counts_train = y_train.value_counts()

    # Liczba obserwacji dla klas 0 i 1 w zbiorze testowym
    class_counts_test = y_test.value_counts()

    return balance_train, class_counts_train[0], class_counts_train[1], balance_test, class_counts_test[0], class_counts_test[1]

num_seeds = 10
best_seed = None
best_balance = float('inf')

for seed in range(num_seeds):
    balance_train, class_0_count_train, class_1_count_train, balance_test, class_0_count_test, class_1_count_test = calculate_balance(seed)
    print(f"Seed: {seed}, Train Balance: {balance_train}, Class 0 count (train): {class_0_count_train}, Class 1 count (train): {class_1_count_train}, Test Balance: {balance_test}, Class 0 count (test): {class_0_count_test}, Class 1 count (test): {class_1_count_test}")

    if balance_train < best_balance:
        best_balance = balance_train
        best_seed = seed

print(f"\nNajlepszy seed: {best_seed}, Najlepsze zbalansowanie (train): {best_balance}")

# Ostateczny podział danych dla najlepszego seeda
X_train, X_test, y_train, y_test = train_test_split(encoded_data.drop('HeartDisease', axis=1),
                                                    encoded_data['HeartDisease'],
                                                    test_size=0.2,
                                                    random_state=best_seed)

# Wyświetlenie liczby 0 i 1 w zbiorze uczącym (dla najlepszego seeda)
print(f"Liczba obserwacji w zbiorze uczącym (klasa 0): {y_train.value_counts()[0]}")
print(f"Liczba obserwacji w zbiorze uczącym (klasa 1): {y_train.value_counts()[1]}")

# Wyświetlenie liczby 0 i 1 w zbiorze testowym (dla najlepszego seeda)
print(f"Liczba obserwacji w zbiorze testowym (klasa 0): {y_test.value_counts()[0]}")
print(f"Liczba obserwacji w zbiorze testowym (klasa 1): {y_test.value_counts()[1]}")

"""Dla zbioru uczącego i testowego przetestowno rózne random seedy w celu wybrania najbardziej zbalansowanego zbioru uczącego i testowego. Liczba 0 oraz 1 powinna być maksymalnie zbliżona zarónwo na zbiorze uczącym jak i testowym. Dla wybranego zestawu danych najlepszym random seedem jest 5, dla którego mamy dla zbioru uczącego odpowiednio 337 obserwacji z wartościa zmiennej objasnianej 0, 397 z wartością 1. Dla zbioru testowego mamy odpowiedniu 73 obserwacji z wartościami 0 oraz 111 obserwacji z wartościami 1.

"""

X_train, X_test, y_train, y_test = train_test_split(encoded_data.drop('HeartDisease', axis=1),
                                                        encoded_data['HeartDisease'],
                                                        test_size=0.2,
                                                        random_state=5)

X_train.info()

"""#Metody uczenia maszynowego

## Lasy losowe

Implementacja lasów losowych dla zbioru
"""

# Parametry do przetestowania
n_estimators_values = [70, 100, 150, 200]  # różne liczby drzew w lesie
max_features_values = [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]  # różna liczba zmiennych w podziale

best_test_accuracy = 0
best_test_sensitivity = 0
best_train_accuracy = 0
best_train_sensitivity = 0
best_test_params = {}
best_train_params = {}

# Tworzenie siatki wyników dla zbioru testowego
test_sensitivity_grid = np.zeros((len(n_estimators_values), len(max_features_values)))
test_accuracy_grid = np.zeros((len(n_estimators_values), len(max_features_values)))

# Tworzenie siatki wyników dla zbioru treningowego
train_sensitivity_grid = np.zeros((len(n_estimators_values), len(max_features_values)))
train_accuracy_grid = np.zeros((len(n_estimators_values), len(max_features_values)))

for i, n_estimators in enumerate(n_estimators_values):
    for j, max_features in enumerate(max_features_values):
        rf_model = RandomForestClassifier(n_estimators=n_estimators, max_features=max_features, random_state=42)
        rf_model.fit(X_train, y_train)

        # Predykcja na zbiorze testowym
        y_pred_rf_test = rf_model.predict(X_test)
        true_positive_test = np.sum((y_test == 1) & (y_pred_rf_test == 1))
        false_negative_test = np.sum((y_test == 1) & (y_pred_rf_test == 0))
        sensitivity_test = true_positive_test / (true_positive_test + false_negative_test)
        test_sensitivity_grid[i][j] = sensitivity_test

        accuracy_test = accuracy_score(y_test, y_pred_rf_test)
        test_accuracy_grid[i][j] = accuracy_test

        # Predykcja na zbiorze treningowym
        y_pred_rf_train = rf_model.predict(X_train)
        true_positive_train = np.sum((y_train == 1) & (y_pred_rf_train == 1))
        false_negative_train = np.sum((y_train == 1) & (y_pred_rf_train == 0))
        sensitivity_train = true_positive_train / (true_positive_train + false_negative_train)
        train_sensitivity_grid[i][j] = sensitivity_train

        accuracy_train = accuracy_score(y_train, y_pred_rf_train)
        train_accuracy_grid[i][j] = accuracy_train

        # Aktualizacja najlepszych wyników dla zbioru testowego
        if accuracy_test > best_test_accuracy:
            best_test_accuracy = accuracy_test
            best_test_sensitivity = sensitivity_test
            best_test_params = {"n_estimators": n_estimators, "max_features": max_features}

        # Aktualizacja najlepszych wyników dla zbioru treningowego
        if accuracy_train > best_train_accuracy:
            best_train_accuracy = accuracy_train
            best_train_sensitivity = sensitivity_train
            best_train_params = {"n_estimators": n_estimators, "max_features": max_features}

# Wypisanie najlepszych parametrów i wyników dla zbioru testowego
print("Najlepsze parametry dla zbioru testowego:")
print(best_test_params)
print(f"Najlepsza czułość dla zbioru testowego: {best_test_sensitivity}")
print(f"Najlepsza dokładność dla zbioru testowego: {best_test_accuracy}")

# Wypisanie najlepszych parametrów i wyników dla zbioru treningowego
print("\nNajlepsze parametry dla zbioru treningowego:")
print(best_train_params)
print(f"Najlepsza czułość dla zbioru treningowego: {best_train_sensitivity}")
print(f"Najlepsza dokładność dla zbioru treningowego: {best_train_accuracy}")

# Parametry do przetestowania
n_estimators_values = [10, 50, 70, 100, 150, 200]  # różne liczby drzew w lesie
max_features_values = [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]  # różna liczba zmiennych w podziale

best_test_accuracy = 0
best_test_sensitivity = 0
best_test_params = {}
best_train_accuracy = 0
best_train_sensitivity = 0
best_train_params = {}

# Tworzenie siatki wyników dla zbioru testowego
test_sensitivity_grid = np.zeros((len(n_estimators_values), len(max_features_values)))
test_accuracy_grid = np.zeros((len(n_estimators_values), len(max_features_values)))

# Tworzenie siatki wyników dla zbioru treningowego
train_sensitivity_grid = np.zeros((len(n_estimators_values), len(max_features_values)))
train_accuracy_grid = np.zeros((len(n_estimators_values), len(max_features_values)))

for i, n_estimators in enumerate(n_estimators_values):
    for j, max_features in enumerate(max_features_values):
        rf_model = RandomForestClassifier(n_estimators=n_estimators, max_features=max_features, random_state=42)

        # Walidacja krzyżowa na zbiorze treningowym
        kfold = KFold(n_splits=5, shuffle=True, random_state=42)
        cv_results_train = cross_val_score(rf_model, X_train, y_train, cv=kfold, scoring='accuracy')

        accuracy_cv_train = np.mean(cv_results_train)

        # Predykcja na zbiorze testowym
        rf_model.fit(X_train, y_train)
        y_pred_rf_test = rf_model.predict(X_test)

        true_positive_test = np.sum((y_test == 1) & (y_pred_rf_test == 1))
        false_negative_test = np.sum((y_test == 1) & (y_pred_rf_test == 0))
        sensitivity_test = true_positive_test / (true_positive_test + false_negative_test)
        test_sensitivity_grid[i][j] = sensitivity_test

        accuracy_test = accuracy_score(y_test, y_pred_rf_test)
        test_accuracy_grid[i][j] = accuracy_test

        # Aktualizacja wyników dla zbioru treningowego
        if accuracy_cv_train > best_train_accuracy:
            best_train_accuracy = accuracy_cv_train
            best_train_sensitivity = np.mean(cross_val_score(rf_model, X_train, y_train, cv=kfold, scoring='recall'))
            best_train_params = {"n_estimators": n_estimators, "max_features": max_features}

        # Aktualizacja wyników dla zbioru testowego
        if accuracy_test > best_test_accuracy:
            best_test_accuracy = accuracy_test
            best_test_sensitivity = sensitivity_test
            best_test_params = {"n_estimators": n_estimators, "max_features": max_features}

# Wypisanie najlepszych parametrów i wyników dla zbioru treningowego
print("Najlepsze parametry dla zbioru treningowego:")
print(best_train_params)
print(f"Najlepsza dokładność dla zbioru treningowego: {best_train_accuracy}")
print(f"Najlepsza czułość dla zbioru treningowego: {best_train_sensitivity}")

# Wypisanie najlepszych parametrów i wyników dla zbioru testowego
print("\nNajlepsze parametry dla zbioru testowego:")
print(best_test_params)
print(f"Najlepsza dokładność dla zbioru testowego: {best_test_accuracy}")
print(f"Najlepsza czułość dla zbioru testowego: {best_test_sensitivity}")

# Wyświetlenie wykresu czułości dla zbioru testowego
fig, ax1 = plt.subplots()
cax1 = ax1.matshow(test_sensitivity_grid, cmap='viridis')
fig.colorbar(cax1)
ax1.set_xticks(np.arange(len(max_features_values)))
ax1.set_yticks(np.arange(len(n_estimators_values)))
ax1.set_xticklabels(max_features_values)
ax1.set_yticklabels(n_estimators_values)
plt.xlabel('Liczba zmiennych w podziale')
plt.ylabel('Liczba drzew w lesie')
plt.title('Wpływ liczby drzew i zmiennych na czułość')

# Wyświetlenie wykresu dokładności dla zbioru testowego
fig, ax2 = plt.subplots()
cax2 = ax2.matshow(test_accuracy_grid, cmap='viridis')
fig.colorbar(cax2)
ax2.set_xticks(np.arange(len(max_features_values)))
ax2.set_yticks(np.arange(len(n_estimators_values)))
ax2.set_xticklabels(max_features_values)
ax2.set_yticklabels(n_estimators_values)
plt.xlabel('Liczba zmiennych w podziale')
plt.ylabel('Liczba drzew w lesie')
plt.title('Wpływ liczby drzew i zmiennych na dokładność')

plt.show()

"""## Algorytm SVM

### Jądro liniowe

Standaryzacja danych
"""

standardScaler = StandardScaler()
X_train_standarized = standardScaler.fit_transform(X_train)
X_test_standarized = standardScaler.transform(X_test)

# Inicjalizacja modelu SVM z jądrem liniowym
svm_linear = SVC(kernel='linear')

# Hiperparametry do optymalizacji
param_grid_linear = {'C': [0.001, 0.01, 0.1, 1, 2 , 4 , 10 ]}

# Przygotowanie list na wyniki
accuracy_list_linear = []
sensitivity_list_linear = []

# Iteracja po różnych wartościach parametru C
for c in param_grid_linear['C']:
    svm_linear = SVC(kernel='linear', C=c)
    svm_linear.fit(X_train_standarized, y_train)
    y_pred_linear = svm_linear.predict(X_test_standarized)

    # Obliczanie dokładności (accuracy)
    accuracy_linear = accuracy_score(y_test, y_pred_linear)
    accuracy_list_linear.append(accuracy_linear)

    # Obliczanie czułości (sensitivity)
    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_linear).ravel()
    sensitivity_linear = tp / (tp + fn)
    sensitivity_list_linear.append(sensitivity_linear)

# Tworzenie wykresu
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
plt.plot(param_grid_linear['C'], accuracy_list_linear, label='Accuracy')
plt.plot(param_grid_linear['C'], sensitivity_list_linear, label='Sensitivity')
plt.xscale('log')
plt.xlabel('Wartość parametru C')
plt.ylabel('Wynik')
plt.title('Wyniki dla jądra liniowego (linear)')
plt.legend()
plt.grid(True)
plt.show()

"""### Jądro wielomianowe"""

# Inicjalizacja modelu SVM z jądrem wielomianowym
svm_poly = SVC(kernel='poly')

# Hiperparametry do optymalizacji
param_grid_poly = {'C': [0.001, 0.01, 0.1, 1, 2 , 4 , 10 ], 'degree': [2, 3, 4], 'gamma': [0.001, 0.01, 0.1, 1]}

# Przygotowanie list na wyniki
accuracy_list_poly = []
sensitivity_list_poly = []

# Iteracja po różnych kombinacjach parametrów
for c in param_grid_poly['C']:
    for degree in param_grid_poly['degree']:
        for gamma in param_grid_poly['gamma']:
            svm_poly = SVC(kernel='poly', C=c, degree=degree, gamma=gamma)
            svm_poly.fit(X_train_standarized, y_train)
            y_pred_poly = svm_poly.predict(X_test_standarized)

            # Obliczanie dokładności (accuracy)
            accuracy_poly = accuracy_score(y_test, y_pred_poly)
            accuracy_list_poly.append(accuracy_poly)

            # Obliczanie czułości (sensitivity)
            tn, fp, fn, tp = confusion_matrix(y_test, y_pred_poly).ravel()
            sensitivity_poly = tp / (tp + fn)
            sensitivity_list_poly.append(sensitivity_poly)

accuracy_array_poly = np.array(accuracy_list_poly).reshape(len(param_grid_poly['C']), len(param_grid_poly['degree']), len(param_grid_poly['gamma']))
sensitivity_array_poly = np.array(sensitivity_list_poly).reshape(len(param_grid_poly['C']), len(param_grid_poly['degree']), len(param_grid_poly['gamma']))

fig, axes = plt.subplots(len(param_grid_poly['degree']), len(param_grid_poly['gamma']), figsize=(14, 10), sharex='all', sharey='all')

for i in range(len(param_grid_poly['degree'])):
    for j in range(len(param_grid_poly['gamma'])):
        axes[i, j].plot(param_grid_poly['C'], accuracy_array_poly[:, i, j], label='Accuracy')
        axes[i, j].plot(param_grid_poly['C'], sensitivity_array_poly[:, i, j], label='Sensitivity')
        axes[i, j].set_xscale('log')
        axes[i, j].set_xlabel('Wartość parametru C')
        axes[i, j].set_ylabel('Wynik')
        axes[i, j].set_title(f'degree={param_grid_poly["degree"][i]}, gamma={param_grid_poly["gamma"][j]}')
        axes[i, j].legend()
        axes[i, j].grid(True)

plt.tight_layout()
plt.show()

"""### Jądro radialne"""

# Inicjalizacja modelu SVM z jądrem radialnym (RBF)
svm_rbf = SVC(kernel='rbf')

# Hiperparametry do optymalizacji
param_grid_rbf = {'C': [0.001, 0.01, 0.1, 1, 2 , 4 , 10 ], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}

# Przygotowanie list na wyniki
accuracy_list_rbf = []
sensitivity_list_rbf = []

# Iteracja po różnych kombinacjach parametrów
for c in param_grid_rbf['C']:
    for gamma in param_grid_rbf['gamma']:
        svm_rbf = SVC(kernel='rbf', C=c, gamma=gamma)
        svm_rbf.fit(X_train_standarized, y_train)
        y_pred_rbf = svm_rbf.predict(X_test_standarized)

        # Obliczanie dokładności (accuracy)
        accuracy_rbf = accuracy_score(y_test, y_pred_rbf)
        accuracy_list_rbf.append(accuracy_rbf)

        # Obliczanie czułości (sensitivity)
        tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rbf).ravel()
        sensitivity_rbf = tp / (tp + fn)
        sensitivity_list_rbf.append(sensitivity_rbf)

# Tworzenie wykresu
accuracy_array_rbf = np.array(accuracy_list_rbf).reshape(len(param_grid_rbf['C']), len(param_grid_rbf['gamma']))
sensitivity_array_rbf = np.array(sensitivity_list_rbf).reshape(len(param_grid_rbf['C']), len(param_grid_rbf['gamma']))

plt.figure(figsize=(10, 6))
for i in range(len(param_grid_rbf['C'])):
    plt.plot(param_grid_rbf['gamma'], accuracy_array_rbf[i], label=f'C={param_grid_rbf["C"][i]}: Accuracy')
    plt.plot(param_grid_rbf['gamma'], sensitivity_array_rbf[i], label=f'C={param_grid_rbf["C"][i]}: Sensitivity')

plt.xlabel('Wartość parametru gamma')
plt.ylabel('Wynik')
plt.title('Wyniki dla jądra radialnego (RBF)')
plt.legend()
plt.grid(True)
plt.show()

for i in range(len(param_grid_rbf['C'])):
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))

    # Wykres dokładności (accuracy)
    axes[0].plot(param_grid_rbf['gamma'], accuracy_array_rbf[i], label=f'C={param_grid_rbf["C"][i]}: Accuracy', color='blue')
    axes[0].set_xlabel('Wartość parametru gamma')
    axes[0].set_ylabel('Accuracy')
    axes[0].set_title(f'Accuracy dla C={param_grid_rbf["C"][i]}')
    axes[0].legend()
    axes[0].grid(True)

    # Wykres czułości (sensitivity)
    axes[1].plot(param_grid_rbf['gamma'], sensitivity_array_rbf[i], label=f'C={param_grid_rbf["C"][i]}: Sensitivity', color='orange')
    axes[1].set_xlabel('Wartość parametru gamma')
    axes[1].set_ylabel('Sensitivity')
    axes[1].set_title(f'Sensitivity dla C={param_grid_rbf["C"][i]}')
    axes[1].legend()
    axes[1].grid(True)

    plt.tight_layout()
    plt.show()

"""Porównanie modeli"""

# Znajdź indeksy maksymalnych wartości accuracy i sensitivity dla każdego jądra
max_acc_linear_index = accuracy_list_linear.index(max(accuracy_list_linear))
max_sens_linear_index = sensitivity_list_linear.index(max(sensitivity_list_linear))

max_acc_poly_index = accuracy_list_poly.index(max(accuracy_list_poly))
max_sens_poly_index = sensitivity_list_poly.index(max(sensitivity_list_poly))

max_acc_rbf_index = accuracy_list_rbf.index(max(accuracy_list_rbf))
max_sens_rbf_index = sensitivity_list_rbf.index(max(sensitivity_list_rbf))

# Wartości parametrów dla najlepszych wyników
best_params = {
    'Linear': {
        'C': param_grid_linear['C'][max_acc_linear_index],
        'Accuracy': max(accuracy_list_linear),
        'Sensitivity': sensitivity_list_linear[max_sens_linear_index]
    },
    'Poly': {
        'C': param_grid_poly['C'][max_acc_poly_index // (len(param_grid_poly['degree']) * len(param_grid_poly['gamma']))],
        'Degree': param_grid_poly['degree'][(max_acc_poly_index // len(param_grid_poly['gamma'])) % len(param_grid_poly['degree'])],
        'Gamma': param_grid_poly['gamma'][max_acc_poly_index % len(param_grid_poly['gamma'])],
        'Accuracy': max(accuracy_list_poly),
        'Sensitivity': sensitivity_list_poly[max_sens_poly_index]
    },
    'RBF': {
        'C': param_grid_rbf['C'][max_acc_rbf_index // len(param_grid_rbf['gamma'])],
        'Gamma': param_grid_rbf['gamma'][max_acc_rbf_index % len(param_grid_rbf['gamma'])],
        'Accuracy': max(accuracy_list_rbf),
        'Sensitivity': sensitivity_list_rbf[max_sens_rbf_index]
    }
}

# Wypisanie wyników
print("Najlepsze wyniki dla różnych jąder:")
for kernel, params in best_params.items():
    print(f"Jądro: {kernel}")
    print(f" - Parametry: {params}")

"""##Algorytm KNN"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import chi2_contingency
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score




# Listy do przechowywania wyników
accuracy_train_scores = []
precision_train_scores = []
recall_train_scores = []
specificity_train_scores = []

accuracy_test_scores = []
precision_test_scores = []
recall_test_scores = []
specificity_test_scores = []

# Przetestowanie różnych wartości parametru k

for k in range(1, 21):
    # Inicjalizacja modelu KNN z aktualnym parametrem k
    knn_model = KNeighborsClassifier(n_neighbors=k)

    # Trenowanie modelu na zbiorze treningowym
    knn_model.fit(X_train, y_train)

    # Prognozowanie na zbiorze treningowym
    y_train_pred = knn_model.predict(X_train)

    # Ocena modelu na zbiorze treningowym
    accuracy_train = accuracy_score(y_train, y_train_pred)
    precision_train = precision_score(y_train, y_train_pred)
    recall_train = recall_score(y_train, y_train_pred)

    # Obliczenie specyficzności
    tn, fp, fn, tp = confusion_matrix(y_train, y_train_pred).ravel()
    specificity_train = tn / (tn + fp)

    accuracy_train_scores.append(accuracy_train)
    precision_train_scores.append(precision_train)
    recall_train_scores.append(recall_train)
    specificity_train_scores.append(specificity_train)

    # Prognozowanie na zbiorze testowym
    y_test_pred = knn_model.predict(X_test)

    # Ocena modelu na zbiorze testowym
    accuracy_test = accuracy_score(y_test, y_test_pred)
    precision_test = precision_score(y_test, y_test_pred)
    recall_test = recall_score(y_test, y_test_pred)

    # Obliczenie specyficzności
    tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()
    specificity_test = tn / (tn + fp)

    accuracy_test_scores.append(accuracy_test)
    precision_test_scores.append(precision_test)
    recall_test_scores.append(recall_test)
    specificity_test_scores.append(specificity_test)

# Wykresy
plt.figure(figsize=(12, 12))

# Wykres dokładności
plt.subplot(3, 2, 1)
plt.plot(range(1, 21), accuracy_train_scores, marker='o', label='Treningowy')
plt.plot(range(1, 21), accuracy_test_scores, marker='o', label='Testowy')
plt.title('Dokładność dla różnych k')
plt.xlabel('k (liczba sąsiadów)')
plt.ylabel('Dokładność')
plt.legend()

# Wykres precyzji
plt.subplot(3, 2, 3)
plt.plot(range(1, 21), precision_train_scores, marker='o', color='green', label='Treningowy')
plt.plot(range(1, 21), precision_test_scores, marker='o', color='green', linestyle='dashed', label='Testowy')
plt.title('Precyzja dla różnych k')
plt.xlabel('k (liczba sąsiadów)')
plt.ylabel('Precyzja')
plt.legend()

# Wykres czułości
plt.subplot(3, 2, 5)
plt.plot(range(1, 21), recall_train_scores, marker='o', color='orange', label='Treningowy')
plt.plot(range(1, 21), recall_test_scores, marker='o', color='orange', linestyle='dashed', label='Testowy')
plt.title('Czułość dla różnych k')
plt.xlabel('k (liczba sąsiadów)')
plt.ylabel('Czułość')
plt.legend()

plt.tight_layout()
plt.show()

# Tabela z wynikami
results_df = pd.DataFrame({
    'k': list(range(1, 21)),
    'AccTrain': accuracy_train_scores,
    'AccTest': accuracy_test_scores,
    'PrecTrain': precision_train_scores,
    'PrecTest': precision_test_scores,
    'RecallTrain': recall_train_scores,
    'RecallTest': recall_test_scores,
    'SpecTrain': specificity_train_scores,
    'SpecTest': specificity_test_scores
})

print("\nTabela wyników:")
print(results_df)

k7_results_train = pd.DataFrame({
    'Parametr': ['Accuracy', 'Precision', 'Recall', 'Specificity'],
    'Wartość': [accuracy_train_scores[7], precision_train_scores[7],
                recall_train_scores[7], specificity_train_scores[7]]
})

k7_results_test = pd.DataFrame({
    'Parametr': ['Accuracy', 'Precision', 'Recall', 'Specificity'],
    'Wartość': [accuracy_test_scores[7], precision_test_scores[7],
                recall_test_scores[7], specificity_test_scores[7]]
})
print("Wyniki dla K=7 dla zbioru treningowego:")
print(k7_results_train)

print("\nWyniki dla K=7 dla zbioru testowego:")
print(k7_results_test)

"""Porównanie algorytmu knn na danych bez standaryzacji i z standaryzacją"""

from sklearn.metrics import accuracy_score, recall_score

# Standaryzacja danych
standardScaler = StandardScaler()
X_train_standarized = standardScaler.fit_transform(X_train)
X_test_standarized = standardScaler.transform(X_test)

# Inicjacja modelu KNN
knn = KNeighborsClassifier(n_neighbors=7)

# Trenowanie modelu na danych ze standaryzacją
knn.fit(X_train_standarized, y_train)

# Przewidywanie na danych ze standaryzacją
y_pred_standarized = knn.predict(X_test_standarized)

# Obliczenie dokładności i czułości modelu ze standaryzacją na zbiorze testowym
accuracy_standarized_test = accuracy_score(y_test, y_pred_standarized)
recall_standarized_test = recall_score(y_test, y_pred_standarized)

# Obliczenie dokładności i czułości modelu ze standaryzacją na zbiorze treningowym
y_pred_train_standarized = knn.predict(X_train_standarized)
accuracy_standarized_train = accuracy_score(y_train, y_pred_train_standarized)
recall_standarized_train = recall_score(y_train, y_pred_train_standarized)

# Trenowanie modelu na danych bez standaryzacji
knn.fit(X_train, y_train)

# Przewidywanie na danych bez standaryzacji
y_pred = knn.predict(X_test)

# Obliczenie dokładności i czułości modelu bez standaryzacji na zbiorze testowym
accuracy_test = accuracy_score(y_test, y_pred)
recall_test = recall_score(y_test, y_pred)

# Obliczenie dokładności i czułości modelu bez standaryzacji na zbiorze treningowym
y_pred_train = knn.predict(X_train)
accuracy_train = accuracy_score(y_train, y_pred_train)
recall_train = recall_score(y_train, y_pred_train)

# Porównanie wyników
print("Dokładność modelu ze standaryzacją (Test): {:.2f}%".format(accuracy_standarized_test * 100))
print("Czułość modelu ze standaryzacją (Test): {:.2f}%".format(recall_standarized_test * 100))
print("Dokładność modelu bez standaryzacji (Test): {:.2f}%".format(accuracy_test * 100))
print("Czułość modelu bez standaryzacji (Test): {:.2f}%".format(recall_test * 100))

print("\nDokładność modelu ze standaryzacją (Trening): {:.2f}%".format(accuracy_standarized_train * 100))
print("Czułość modelu ze standaryzacją (Trening): {:.2f}%".format(recall_standarized_train * 100))
print("Dokładność modelu bez standaryzacji (Trening): {:.2f}%".format(accuracy_train * 100))
print("Czułość modelu bez standaryzacji (Trening): {:.2f}%".format(recall_train * 100))

"""##Regresja logistyczna"""

from sklearn.linear_model import LogisticRegression

# Standaryzacja danych
standardScaler = StandardScaler()
X_train_standarized = standardScaler.fit_transform(X_train)
X_test_standarized = standardScaler.transform(X_test)

# Inicjacja modelu regresji logistycznej
logistic_regression = LogisticRegression()

# Trenowanie modelu na danych ze standaryzacją
logistic_regression.fit(X_train_standarized, y_train)

# Przewidywanie na danych ze standaryzacją
y_pred_standarized = logistic_regression.predict(X_test_standarized)

# Obliczenie dokładności i czułości modelu ze standaryzacją na zbiorze testowym
accuracy_standarized_test = accuracy_score(y_test, y_pred_standarized)
recall_standarized_test = recall_score(y_test, y_pred_standarized)

# Obliczenie dokładności i czułości modelu ze standaryzacją na zbiorze treningowym
y_pred_train_standarized = logistic_regression.predict(X_train_standarized)
accuracy_standarized_train = accuracy_score(y_train, y_pred_train_standarized)
recall_standarized_train = recall_score(y_train, y_pred_train_standarized)

# Trenowanie modelu na danych bez standaryzacji
logistic_regression.fit(X_train, y_train)

# Przewidywanie na danych bez standaryzacji
y_pred = logistic_regression.predict(X_test)

# Obliczenie dokładności i czułości modelu bez standaryzacji na zbiorze testowym
accuracy_test = accuracy_score(y_test, y_pred)
recall_test = recall_score(y_test, y_pred)

# Obliczenie dokładności i czułości modelu bez standaryzacji na zbiorze treningowym
y_pred_train = logistic_regression.predict(X_train)
accuracy_train = accuracy_score(y_train, y_pred_train)
recall_train = recall_score(y_train, y_pred_train)

# Porównanie wyników
print("Dokładność modelu ze standaryzacją (Test): {:.2f}%".format(accuracy_standarized_test * 100))
print("Czułość modelu ze standaryzacją (Test): {:.2f}%".format(recall_standarized_test * 100))
print("Dokładność modelu bez standaryzacji (Test): {:.2f}%".format(accuracy_test * 100))
print("Czułość modelu bez standaryzacji (Test): {:.2f}%".format(recall_test * 100))

print("\nDokładność modelu ze standaryzacją (Trening): {:.2f}%".format(accuracy_standarized_train * 100))
print("Czułość modelu ze standaryzacją (Trening): {:.2f}%".format(recall_standarized_train * 100))
print("Dokładność modelu bez standaryzacji (Trening): {:.2f}%".format(accuracy_train * 100))
print("Czułość modelu bez standaryzacji (Trening): {:.2f}%".format(recall_train * 100))

"""Testownie róznych wartości parametru 'C'"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, recall_score, make_scorer

# Inicjacja modelu regresji logistycznej z większą liczbą iteracji
logistic_regression = LogisticRegression(max_iter=1000)

# Definicja siatki parametrów do przetestowania
param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}

# Inicjacja obiektu do przeszukiwania siatki
grid_search = GridSearchCV(logistic_regression, param_grid, scoring={'accuracy': make_scorer(accuracy_score), 'recall': make_scorer(recall_score)}, refit='accuracy', cv=5)

# Trenowanie modelu na oryginalnych danych (bez standaryzacji)
grid_search.fit(X_train, y_train)

# Najlepsze parametry
best_params = grid_search.best_params_

# Przewidywanie na oryginalnych danych (bez standaryzacji)
y_pred = grid_search.predict(X_test)

# Obliczenie dokładności i czułości modelu na zbiorze testowym (bez standaryzacji)
accuracy_test = accuracy_score(y_test, y_pred)
recall_test = recall_score(y_test, y_pred)

# Przewidywanie na oryginalnych danych (bez standaryzacji, dla zbioru treningowego)
y_pred_train = grid_search.predict(X_train)

# Obliczenie dokładności i czułości modelu na zbiorze treningowym (bez standaryzacji)
accuracy_train = accuracy_score(y_train, y_pred_train)
recall_train = recall_score(y_train, y_pred_train)

# Wyniki
print("Najlepsze parametry:", best_params)
print("Dokładność modelu (Test): {:.2f}%".format(accuracy_test * 100))
print("Czułość modelu (Test): {:.2f}%".format(recall_test * 100))
print("\nDokładność modelu (Trening): {:.2f}%".format(accuracy_train * 100))
print("Czułość modelu (Trening): {:.2f}%".format(recall_train * 100))

"""#Interpretowalność dla Regresji logistycznej

"""

!pip install dalex

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report
from dalex import Explainer


model_lr = LogisticRegression()
model_lr.fit(X_train, LabelEncoder().fit_transform(y_train))

# Wyświetlenie podsumowania
print(classification_report(LabelEncoder().fit_transform(y_test), model_lr.predict(X_test)))

# Przygotowanie explainera DALEX
exp_lr = Explainer(model_lr, X_train, y_train, label='Logistic regression')

# Profile ceteris-paribus (PCP)
obs = X_train.iloc[10, :]
pcp = exp_lr.predict_profile(obs)
# Profile ceteris-paribus (PCP)
pcp.plot(variables=['Age'])
pcp.plot(variables=['RestingBP'])
pcp.plot(variables=['Cholesterol'])
pcp.plot(variables=['MaxHR'])
pcp.plot(variables=['Oldpeak'])

# Wykresy częściowej zależności (PDP)
# Zmienne ilościowe
pdp_age = exp_lr.model_profile(variables='Age')
pdp_age.plot()
pdp_age.plot(geom='profiles', title='PCP and PDP for Age')

restingBP = exp_lr.model_profile(variables='RestingBP')
restingBP.plot()
restingBP.plot(geom='profiles', title='PCP and PDP for RestingBP')

cholesterol = exp_lr.model_profile(variables='Cholesterol')
cholesterol.plot()
cholesterol.plot(geom='profiles', title='PCP and PDP for Cholesterol')

maxHR = exp_lr.model_profile(variables='MaxHR')
maxHR.plot()
maxHR.plot(geom='profiles', title='PCP and PDP for MaxHR')

oldpeak = exp_lr.model_profile(variables='Oldpeak')
oldpeak.plot()
oldpeak.plot(geom='profiles', title='PCP and PDP for Oldpeak')



# Wartości SHAP
shap_values = exp_lr.predict_parts(obs, type='shap')
shap_values.plot()

# Break-down Plots for Interactions
bd1 = exp_lr.predict_parts(obs, type='break_down_interactions')
bd1.plot()

# Wartości SHAP (uśrednione)
shap_avg = exp_lr.predict_parts(obs, type='shap')
shap_avg.plot()